{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fQqCXgadTfX"
      },
      "source": [
        "# **Unsupervised Learning**\n",
        "\n",
        "The coding questions are independent of the theoretical questions.\n",
        "\n",
        "In this assignment, we will build the simplest models for unsupervised learning for a linear neuron:\n",
        "\n",
        "$$y = \\sum\\limits_{i=1}^{n} w_i x_i. \\tag{1}$$\n",
        "\n",
        "\n",
        "Here ${x_i}$ are input neurons and $w_i$ are the associated synaptic weights. Let's start with the assumption that synaptic weights are increased in proportion to the correlation between pre-synaptic and post-synaptic activity; synchonized firing $‚ü∂$ stronger wiring: \n",
        "\n",
        "\n",
        "$$\\Delta w_i = \\tau <y,x_i>, \\tag{2}$$\n",
        "\n",
        "where $\\Delta w_i$ is the change in the strength of synapse $w_i$ and the parameter $\\tau > 0$ is a slow learning rate.\n",
        "\n",
        "\n",
        "\n",
        "1) Suppose you have $m$ observations for each input $x_i$: $x_i^1,x_i^2,\\cdots,x_i^m$. These observations are faster than the learning rate. After all the observations have occurred, we want to evaluate the synaptic weights. Show that the weights vector $\\mathbf{w}^T={w_1,w_2, ..., w_n}$ is the solution to a differential equation of the form:\n",
        "\n",
        "$$\\gamma \\frac{d \\mathbf{w}}{d t}  = C \\, \\mathbf{w},$$\n",
        "with $\\gamma > 0$ and $C$ is the correlation matrix such that $C_{i,j} =  \\sum\\limits_{i=1}^{m} x_i^m x_j^m$.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apH93r4BUDGn"
      },
      "outputs": [],
      "source": [
        "## Answer here \n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhvEi85sUDGo"
      },
      "source": [
        "2) The dataset \"input.npy\" contains presynaptic activity from two input neurons at random time points. Using the the rules (1) and (2), write a program that simulates the output $y$ and estimates the weights vector ${w_i}$. You can select the points in the data randomly and thus estimate the weights by stochastic gradient ascent. \n",
        "\n",
        "3) Run the program with 150 iterations (select 150 observations out of the 1000) and plot the weights and the data. What is the estimated vector ? Do you understand why ?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "_7Gm8FUwrvTz",
        "outputId": "66a3134d-c07e-4fcd-dc15-27d3bfc73b96"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6a143b48574d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0minputdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mnb_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'input.npy'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "inputdata = np.load('input.npy')\n",
        "\n",
        "nb_samples = inputdata.shape[1]\n",
        "\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(1)\n",
        "\n",
        "\n",
        "# 2 inputs, 1 output (initialize the weights)\n",
        "weights = np.random.rand(2,1) \n",
        "\n",
        "lrate = 0.01 # This rate should work\n",
        "\n",
        "#  CODE THE LOOP HERE AND PLOT RESULTS\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y7C3fYCUDGp"
      },
      "source": [
        "4) Run the function with 300 and 500 iterations (same wights intialization and learning rate) and plot the results. Do you understand why the weights behave this way ? Is it biologically plausible that this happens ?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7bEO-OCUDGp"
      },
      "outputs": [],
      "source": [
        "# Set random seed for reproducibility\n",
        "np.random.seed(1)\n",
        "\n",
        "\n",
        "# CODE and Answer here\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KFliBWDUDGp"
      },
      "source": [
        "From questions (1-4), you might noticed that the pure linear model will make some weights very large while reducing the others to zero. This is sometimes not desirable. Think of a layer 4 neuron taking inputs from two LGN neurons (each associated with an input from the left or the right eye). If one of the weights become very large compared to the other, we would reach a biologically implausible ocular dominance. One way to solve this problem is to constrain the growth of each weight in the following way:\n",
        "\n",
        "$$\\Delta w_i = \\tau (<y,x_i> - \\bar{w}_i y^2), \\tag{3}$$\n",
        "\n",
        "where $\\bar{w}_i$ is the current weights. This way, we make sure the weights are bounded.\n",
        "\n",
        "\n",
        "5) Update the program you wrote before to perform rule (3). Run the function with $2000$ iterations. Comment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23lboXZYaTUT"
      },
      "outputs": [],
      "source": [
        "# Set random seed for reproducibility\n",
        "np.random.seed(1)\n",
        "\n",
        "\n",
        "# CODE and Answer here\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF5NFSwNUDGq"
      },
      "source": [
        "Let's consider the case of multipe linear neurons each following rule (1):\n",
        "\n",
        "$$y_j = \\sum\\limits_{i=1}^{n} w_{ij} x_i. \\tag{4}$$\n",
        "\n",
        "One method to estimate the weights is by generalizing rule (3) in the following way:\n",
        "\n",
        "$$\\Delta w_{ij} = \\tau (<y_j,x_i> -  y_j \\sum\\limits_{k \\leq j}\\bar{w}_{i,k} \\, y_k), \\tag{5}$$\n",
        "\n",
        "For the first output neuron, this rule is the same as rule (3). The following weights are updated by taking the residuals from previous weights.\n",
        "\n",
        "6) Update your program in order to take into account multiple neurons following rule (5). Run the program with two output neurons using the same data and plot the weights. \n",
        "\n",
        "(This algorithm might have trouble converging. Use $20000$ iterations and initialize the weights randomly like in the other questions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQE79I7eKAeU"
      },
      "outputs": [],
      "source": [
        "# Set random seed for reproducibility\n",
        "np.random.seed(1)\n",
        "\n",
        "\n",
        "# CODE and Answer here\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HG1xcnsuUDGq"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "LearningPCA.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
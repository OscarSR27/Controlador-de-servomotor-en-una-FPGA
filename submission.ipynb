{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "submission.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OscarSR27/Controlador-de-servomotor-en-una-FPGA/blob/master/submission.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR3e4g1xmboV"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def estimate_rf(st,sp,num_window):\n",
        "\n",
        "  spike_assert, = np.where(sp == 1)#find the indexes where the neuron fires (the spikes). So this array contains the indexes\n",
        "  spike_assert = spike_assert[spike_assert >= num_window]#We are interested in the n before stimulus that generates the spikes (n = num_window)\n",
        "                                                         #So, this line says, rewrite the array spike_assert with the values that are greater than num_window\n",
        "                                                         #This also prevents us to find stimulus in for example time = -100 bins (if window is 100). Since spike_assert\n",
        "                                                         #is ordered from the small to bigger number, this works fine\n",
        "  \n",
        "  frames_of_interest = []\n",
        "  for i in range(len(spike_assert)):\n",
        "    array = []\n",
        "    for w in range(num_window):\n",
        "      array.append(st[:,:,spike_assert[i]-(num_window-w)])\n",
        "    frames_of_interest.append(array)\n",
        "  rf = np.mean(frames_of_interest, axis = (1))\n",
        "  rf = np.mean(rf, axis = (0))\n",
        "  return rf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hp8wSpXyON2R"
      },
      "source": [
        "def estimate_nl(st, sp, rf, K):\n",
        "  n = 1\n",
        "  return n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_pI1rAiixD6"
      },
      "source": [
        "def generate_spikes(N,rate,duration):\n",
        "\n",
        "  spikes = []\n",
        "  for i in range(N):\n",
        "    spikes_per_neuron = np.random.rand(duration) < rate/1000\n",
        "    spikes.append(spikes_per_neuron)\n",
        "\n",
        "  return spikes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HhGXyQOoDpq"
      },
      "source": [
        "def mle_fr(spikes):\n",
        "  #MLE for a poisson process is the sum of all observations divided by the total amount of observations\n",
        "  shape = np.shape(spikes)\n",
        "  rate = (np.count_nonzero(spikes)/shape[0])*(1000/shape[1])\n",
        "\n",
        "  return rate"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}